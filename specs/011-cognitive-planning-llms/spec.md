# Feature Specification: Cognitive Planning with LLMs

**Feature Branch**: `011-cognitive-planning-llms`  
**Created**: 2025-12-07  
**Status**: Draft  
**Input**: User description: "Module 4, Chapter 4.2: Cognitive Planning with LLMs Target audience: Students focused on high-level robot control and decision-making. Focus: Using Large Language Models (LLMs) to bridge human intention to technical robot actions. Success criteria: - **Cognitive Planning:** Clearly defines the role of the LLM: translating a goal (""Clean the room"") into a sequence of low-level **ROS 2 actions** (e.g., Navigate to X, Grasp Y, Deposit Z). - **Prompt Engineering:** Provides a template for the system prompt used to instruct the LLM on valid ROS 2 actions (the robot's API). - **Action Sequence:** Demonstrates a simplified example of the LLM outputting a structured action sequence (e.g., JSON or YAML). Constraints: - **Output:** Docusaurus markdown file (`04-vla/llm-cognitive-planning.mdx`). - **Focus:** Emphasis on the **reasoning** and **translation** step of the VLA loop. - **Tools:** Requires discussion of how the LLM communicates with the ROS 2 system (e.g., via a ROS 2 Service call). Not building: - Training a custom LLM from scratch. - Detailed implementation of the final action controllers (already covered in Module 1)."

## User Scenarios & Testing *(mandatory)*

### User Story 1 - Understand LLM Role in Cognitive Planning (Priority: P1)

Readers will clearly define the LLM's role: translating a high-level goal into a sequence of low-level ROS 2 actions.

**Why this priority**: Fundamental concept for using LLMs for high-level robot control.

**Independent Test**: Reader can explain how an LLM converts abstract goals into concrete robot actions.

**Acceptance Scenarios**:

1. **Given** a high-level human command like "Clean the room", **When** the LLM processes it, **Then** the reader understands it is translated into executable ROS 2 actions (e.g., Navigate, Grasp).
2. **Given** an understanding of robot capabilities, **When** the reader learns about cognitive planning, **Then** they can explain how an LLM bridges the gap between human intention and robot API.

---

### User Story 2 - Develop System Prompt for LLM (Priority: P2)

Readers will be provided with a template for the system prompt used to instruct the LLM on valid ROS 2 actions.

**Why this priority**: Practical application of prompt engineering for effective LLM integration.

**Independent Test**: Reader can adapt the provided prompt template to define a new set of valid ROS 2 actions for the robot.

**Acceptance Scenarios**:

1. **Given** a set of available ROS 2 actions, **When** the reader uses the prompt template, **Then** they can construct a system prompt to guide the LLM's action generation.
2. **Given** an LLM integration, **When** a system prompt is applied, **Then** the LLM's output adheres to the defined structure of ROS 2 actions.

---

### User Story 3 - Demonstrate LLM Action Sequence Output (Priority: P3)

Readers will see a simplified example of the LLM outputting a structured action sequence (e.g., JSON or YAML).

**Why this priority**: Illustrates the tangible output format from the LLM that the robot will then execute.

**Independent Test**: Reader can interpret a simplified structured action sequence generated by an LLM.

**Acceptance Scenarios**:

1. **Given** an LLM's output for a robot task, **When** it's in JSON or YAML format, **Then** the reader can identify the sequence of actions the robot is intended to perform.
2. **Given** a structured action sequence, **When** the reader understands its purpose, **Then** they can explain how this output can be parsed and executed by the robot's control system.

### Edge Cases

- None explicitly defined in prompt.

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: The chapter MUST clearly define the role of the LLM: translating a goal ("Clean the room") into a sequence of low-level ROS 2 actions (e.g., Navigate to X, Grasp Y, Deposit Z).
- **FR-002**: The chapter MUST provide a template for the system prompt used to instruct the LLM on valid ROS 2 actions (the robot's API).
- **FR-003**: The chapter MUST demonstrate a simplified example of the LLM outputting a structured action sequence (e.g., JSON or YAML).
- **FR-004**: The chapter MUST emphasize the reasoning and translation step of the VLA loop.
- **FR-005**: The chapter MUST discuss how the LLM communicates with the ROS 2 system (e.g., via a ROS 2 Service call).
- **FR-006**: The chapter MUST be formatted as a Docusaurus markdown file (`04-vla/llm-cognitive-planning.mdx`).

### Non-Functional Requirements

- **NFR-001**: The chapter MUST be targeted at students focused on high-level robot control and decision-making.

### Key Entities (Conceptual)

- **Large Language Model (LLM)**: An AI model capable of understanding and generating human-like text.
- **Cognitive Planning**: Using an LLM to translate high-level goals into executable robot actions.
- **ROS 2 Actions**: Defined, goal-oriented communication patterns in ROS 2.
- **Prompt Engineering**: Designing effective prompts to guide LLM behavior.
- **VLA (Vision-Language-Action) Loop**: A conceptual framework for intelligent robot systems.

### Explicit Out-of-Scope

- Training a custom LLM from scratch.
- Detailed implementation of the final action controllers (already covered in Module 1).

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: The chapter clearly defines the role of the LLM: translating a goal ("Clean the room") into a sequence of low-level ROS 2 actions.
- **SC-002**: The chapter provides a template for the system prompt used to instruct the LLM on valid ROS 2 actions.
- **SC-003**: The chapter demonstrates a simplified example of the LLM outputting a structured action sequence (e.g., JSON or YAML).
